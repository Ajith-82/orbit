# Config for commercial providers (OpenAI, Anthropic, etc.)
general:
  port: 3000
  verbose: false
  https:
    enabled: true
    port: 3443
    cert_file: "./cert.pem"
    key_file: "./key.pem"
  session_id:
    header_name: "X-Session-ID"
    required: true
  inference_provider: "openai"
  language_detection: true
  inference_only: false
  adapter: "qa-vector-chroma"

messages:
  no_results_response: "I'm sorry, but I don't have any specific information about that topic in my knowledge base."
  collection_not_found: "I couldn't find the requested collection. Please make sure the collection exists before querying it."

embedding:
  provider: "openai"
  enabled: true

api_keys:
  header_name: "X-API-Key"
  prefix: "orbit_"

logging:
  level: "INFO"
  handlers:
    file:
      enabled: true
      directory: "logs"
      filename: "orbit-commercial.log"
      max_size_mb: 50
      backup_count: 30
      rotation: "midnight"
      format: "json"
    console:
      enabled: false
  capture_warnings: true
  propagate: false

internal_services:
  mongodb:
    host: ${INTERNAL_SERVICES_MONGODB_HOST}
    port: ${INTERNAL_SERVICES_MONGODB_PORT}
    database: "orbit"
    apikey_collection: "api_keys"
    username: ${INTERNAL_SERVICES_MONGODB_USERNAME}
    password: ${INTERNAL_SERVICES_MONGODB_PASSWORD}

  redis:
    enabled: true
    host: ${INTERNAL_SERVICES_REDIS_HOST}
    port: ${INTERNAL_SERVICES_REDIS_PORT}
    db: 0
    username: ${INTERNAL_SERVICES_REDIS_USERNAME}
    password: ${INTERNAL_SERVICES_REDIS_PASSWORD}
    use_ssl: true
    ttl: 3600

chat_history:
  enabled: false

file_upload:
  enabled: true
  max_size_mb: 10
  max_files_per_batch: 10
  allowed_extensions:
    - ".txt"
    - ".pdf"
    - ".docx"
    - ".doc"
    - ".xlsx"
    - ".xls"
    - ".csv"
    - ".md"
    - ".json"
  upload_directory: "uploads"
  save_to_disk: true
  auto_store_in_vector_db: true
  chunk_size: 1000
  chunk_overlap: 200

embeddings:
  openai:
    api_key: ${OPENAI_API_KEY}
    model: "text-embedding-3-large"
    dimensions: 3072
    batch_size: 10
  cohere:
    api_key: ${COHERE_API_KEY}
    model: "embed-english-v3.0"
    input_type: "search_document"
    dimensions: 1024
    batch_size: 32
    truncate: "NONE"
    embedding_types: ["float"]
  jina:
    api_key: ${JINA_API_KEY}
    base_url: "https://api.jina.ai/v1"
    model: "jina-embeddings-v3"
    task: "text-matching"
    dimensions: 1024
    batch_size: 10

adapters:
  - name: "qa-vector-chroma"
    type: "retriever"
    datasource: "chroma"
    adapter: "qa"
    implementation: "retrievers.implementations.qa.QAChromaRetriever"
    config:
      confidence_threshold: 0.3
      distance_scaling_factor: 200.0
      max_results: 5
      return_results: 3

  - name: "file-vector"
    type: "retriever"
    datasource: "chroma"
    adapter: "file"
    implementation: "retrievers.implementations.file.FileChromaRetriever"
    config:
      confidence_threshold: 0.1
      distance_scaling_factor: 150.0
      max_results: 10
      return_results: 5
      include_file_metadata: true
      boost_file_uploads: true
      file_content_weight: 1.5
      metadata_weight: 0.8

datasources:
  chroma:
    use_local: true
    db_path: "examples/chroma/chroma_db"

inference:
  openai:
    api_key: ${OPENAI_API_KEY}
    model: "gpt-4o-mini"
    temperature: 0.1
    top_p: 0.8
    max_tokens: 1024
    stream: true
  anthropic:
    api_key: ${ANTHROPIC_API_KEY}
    api_base: "https://api.anthropic.com/v1"
    model: "claude-3-haiku-20240307"
    temperature: 0.1
    top_p: 0.8
    max_tokens: 1024
    stream: true
  gemini:
    api_key: ${GOOGLE_API_KEY}
    model: "gemini-2.0-flash"
    temperature: 0.1
    top_p: 0.8
    top_k: 20
    max_tokens: 1024
    stream: true
  groq:
    api_key: ${GROQ_API_KEY}
    model: "llama3-8b-8192"
    temperature: 0.1
    top_p: 0.8
    max_tokens: 1024
    stream: true
  cohere:
    api_key: ${COHERE_API_KEY}
    api_base: "https://api.cohere.ai/v1"
    model: "command-r-plus"
    temperature: 0.1
    top_p: 0.8
    max_tokens: 1024
    stream: true
  mistral:
    api_key: ${MISTRAL_API_KEY}
    api_base: "https://api.mistral.ai/v1"
    model: "mistral-small-latest"
    temperature: 0.1
    top_p: 0.8
    max_tokens: 1024
    stream: true

safety:
  enabled: false

llm_guard:
  enabled: false

reranker:
  enabled: false 